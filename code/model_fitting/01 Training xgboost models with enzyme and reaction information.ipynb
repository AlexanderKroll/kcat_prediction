{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key text.latex.preview in file CCB_plot_style_0v4.mplstyle, line 55 ('text.latex.preview  : False')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key mathtext.fallback_to_cm in file CCB_plot_style_0v4.mplstyle, line 63 ('mathtext.fallback_to_cm : True ## When True, use symbols from the Computer Modern fonts')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.2/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "from os.path import join\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy import stats\n",
    "import xgboost as xgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib as mpl\n",
    "plt.style.use('CCB_plot_style_0v4.mplstyle')\n",
    "c_styles      = mpl.rcParams['axes.prop_cycle'].by_key()['color']   # fetch the defined color styles\n",
    "high_contrast = ['#004488', '#DDAA33', '#BB5566', '#000000']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading training and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3421, 850)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_pickle(join(\"..\", \"..\", \"data\", \"kcat_data\", \"splits\", \"train_df_kcat.pkl\"))\n",
    "data_test = pd.read_pickle(join(\"..\", \"..\", \"data\", \"kcat_data\", \"splits\", \"test_df_kcat.pkl\"))\n",
    "\n",
    "\n",
    "data_train.rename(columns = {\"geomean_kcat\" :\"log10_kcat\"}, inplace = True)\n",
    "data_test.rename(columns = {\"geomean_kcat\" :\"log10_kcat\"}, inplace = True)\n",
    "len(data_train), len(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = list(np.load(join(\"..\", \"..\", \"data\", \"kcat_data\", \"splits\", \"CV_train_indices.npy\"), allow_pickle = True))\n",
    "test_indices = list(np.load(join(\"..\", \"..\", \"data\", \"kcat_data\", \"splits\", \"CV_test_indices.npy\"), allow_pickle = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Training a model with only sequence information (ESM-1b):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Creating input matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ESM1b = np.array(list(data_train[\"ESM1b\"]))\n",
    "train_X = train_ESM1b\n",
    "train_Y = np.array(list(data_train[\"log10_kcat\"]))\n",
    "\n",
    "test_ESM1b = np.array(list(data_test[\"ESM1b\"]))\n",
    "test_X = test_ESM1b\n",
    "test_Y = np.array(list(data_test[\"log10_kcat\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Hyperparameter optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''def cross_validation_mse_gradient_boosting(param):\n",
    "    num_round = param[\"num_rounds\"]\n",
    "    del param[\"num_rounds\"]\n",
    "    param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "    param[\"tree_method\"] = \"gpu_hist\"\n",
    "    param[\"sampling_method\"] = \"gradient_based\"\n",
    "    \n",
    "    MSE = []\n",
    "    R2 = []\n",
    "    for i in range(5):\n",
    "        train_index, test_index  = train_indices[i], test_indices[i]\n",
    "        dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "        dvalid = xgb.DMatrix(train_X[test_index])\n",
    "        bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "        y_valid_pred = bst.predict(dvalid)\n",
    "        MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "        R2.append(r2_score(np.reshape(train_Y[test_index], (-1)),  y_valid_pred))\n",
    "    return(-np.mean(R2))\n",
    "\n",
    "\n",
    "from hyperopt import fmin, tpe, rand, hp, Trials\n",
    "\n",
    "space_gradient_boosting = {\n",
    "    \"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 1),\n",
    "    \"max_depth\": hp.uniform(\"max_depth\", 4,12),\n",
    "    #\"subsample\": hp.uniform(\"subsample\", 0.7, 1),\n",
    "    \"reg_lambda\": hp.uniform(\"reg_lambda\", 0, 5),\n",
    "    \"reg_alpha\": hp.uniform(\"reg_alpha\", 0, 5),\n",
    "    \"max_delta_step\": hp.uniform(\"max_delta_step\", 0, 5),\n",
    "    \"min_child_weight\": hp.uniform(\"min_child_weight\", 0.1, 15),\n",
    "    \"num_rounds\":  hp.uniform(\"num_rounds\", 20, 200)}\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn = cross_validation_mse_gradient_boosting, space = space_gradient_boosting,\n",
    "            algo=rand.suggest, max_evals = 200, trials=trials)''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Training and validating model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'learning_rate': 0.051447544749765035,\n",
    "         'max_delta_step': 2.956459783615207,\n",
    "         'max_depth': 5.034202474908222,\n",
    "         'min_child_weight': 7.457989829577018,\n",
    "         'num_rounds': 297.50601395689256,\n",
    "         'reg_alpha': 1.0858835704466614, \n",
    "         'reg_lambda': 1.1385559144302175}\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "\n",
    "del param[\"num_rounds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6156521084065655, 0.5927689215737512, 0.5450373027741603, 0.6635468722921142, 0.5465250301214235]\n",
      "[0.8251322874089426, 0.8206497271502332, 0.9401031382230501, 0.9269849644397952, 1.061793264104686]\n",
      "[0.3720653400563064, 0.34881598167570627, 0.2894002515317964, 0.4219034383575203, 0.2977699878192147]\n"
     ]
    }
   ],
   "source": [
    "R2 = []\n",
    "MSE = []\n",
    "Pearson = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "    dvalid = xgb.DMatrix(train_X[test_index])\n",
    "    \n",
    "    bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "    \n",
    "    y_valid_pred = bst.predict(dvalid)\n",
    "    MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "    R2.append(r2_score(np.reshape(train_Y[test_index], (-1)), y_valid_pred))\n",
    "    Pearson.append(stats.pearsonr(np.reshape(train_Y[test_index], (-1)), y_valid_pred)[0])\n",
    "\n",
    "print(Pearson)\n",
    "print(MSE)\n",
    "print(R2)\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", \"training_results\", \"Pearson_CV_xgboost_ESM1b.npy\"), np.array(Pearson))\n",
    "np.save(join(\"..\", \"..\", \"data\",  \"training_results\", \"MSE_CV_xgboost_ESM1b.npy\"), np.array(MSE))\n",
    "np.save(join(\"..\", \"..\", \"data\", \"training_results\", \"R2_CV_xgboost_ESM1b.npy\"), np.array(R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.59 0.939 0.345\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "dtest = xgb.DMatrix(test_X)\n",
    "\n",
    "bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "\n",
    "y_test_pred = bst.predict(dtest)\n",
    "MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "\n",
    "print(np.round(Pearson[0],3) ,np.round(MSE_dif_fp_test,3), np.round(R2_dif_fp_test,3))\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", \"training_results\", \"y_test_pred_xgboost_ESM1b.npy\"), bst.predict(dtest))\n",
    "np.save(join(\"..\", \"..\", \"data\", \"training_results\", \"y_test_true_xgboost_ESM1b.npy\"), test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training a model with only sequence information (ESM-1b_ts):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Creating input matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ESM1b = np.array(list(data_train[\"ESM1b_ts\"]))\n",
    "train_X = train_ESM1b\n",
    "train_Y = np.array(list(data_train[\"log10_kcat\"]))\n",
    "\n",
    "test_ESM1b = np.array(list(data_test[\"ESM1b_ts\"]))\n",
    "test_X = test_ESM1b\n",
    "test_Y = np.array(list(data_test[\"log10_kcat\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Hyperparameter optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def cross_validation_mse_gradient_boosting(param):\n",
    "    num_round = param[\"num_rounds\"]\n",
    "    del param[\"num_rounds\"]\n",
    "    param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "    param[\"tree_method\"] = \"gpu_hist\"\n",
    "    param[\"sampling_method\"] = \"gradient_based\"\n",
    "    \n",
    "    MSE = []\n",
    "    R2 = []\n",
    "    for i in range(5):\n",
    "        train_index, test_index  = train_indices[i], test_indices[i]\n",
    "        dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "        dvalid = xgb.DMatrix(train_X[test_index])\n",
    "        bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "        y_valid_pred = bst.predict(dvalid)\n",
    "        MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "        R2.append(r2_score(np.reshape(train_Y[test_index], (-1)),  y_valid_pred))\n",
    "    return(-np.mean(R2))\n",
    "\n",
    "\n",
    "from hyperopt import fmin, tpe, rand, hp, Trials\n",
    "\n",
    "space_gradient_boosting = {\n",
    "    \"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 1),\n",
    "    \"max_depth\": hp.uniform(\"max_depth\", 4,12),\n",
    "    #\"subsample\": hp.uniform(\"subsample\", 0.7, 1),\n",
    "    \"reg_lambda\": hp.uniform(\"reg_lambda\", 0, 5),\n",
    "    \"reg_alpha\": hp.uniform(\"reg_alpha\", 0, 5),\n",
    "    \"max_delta_step\": hp.uniform(\"max_delta_step\", 0, 5),\n",
    "    \"min_child_weight\": hp.uniform(\"min_child_weight\", 0.1, 15),\n",
    "    \"num_rounds\":  hp.uniform(\"num_rounds\", 20, 200)}\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn = cross_validation_mse_gradient_boosting, space = space_gradient_boosting,\n",
    "            algo=rand.suggest, max_evals = 200, trials=trials)''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Training and validating model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'learning_rate': 0.2831145406836757,\n",
    "         'max_delta_step': 0.07686715986169101, \n",
    "         'max_depth': 4.96836783761305,\n",
    "          'min_child_weight': 6.905400087083855,\n",
    "           'num_rounds': 313.1498988074061,\n",
    "            'reg_alpha': 1.717314107718892,\n",
    "             'reg_lambda': 2.470354543039016}\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "\n",
    "del param[\"num_rounds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6089419355661412, 0.5895091873624034, 0.5917286045189503, 0.642803324015263, 0.5233641744058668]\n",
      "[0.830309790220053, 0.8254878887860261, 0.8642504226487573, 0.9497311132104741, 1.1100478926967097]\n",
      "[0.3681252040118652, 0.3449769094978131, 0.34673536553812156, 0.4077182348220084, 0.26585619671739524]\n"
     ]
    }
   ],
   "source": [
    "R2 = []\n",
    "MSE = []\n",
    "Pearson = []\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "    dvalid = xgb.DMatrix(train_X[test_index])\n",
    "    \n",
    "    bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "    \n",
    "    y_valid_pred = bst.predict(dvalid)\n",
    "    MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "    R2.append(r2_score(np.reshape(train_Y[test_index], (-1)), y_valid_pred))\n",
    "    Pearson.append(stats.pearsonr(np.reshape(train_Y[test_index], (-1)), y_valid_pred)[0])\n",
    "\n",
    "print(Pearson)\n",
    "print(MSE)\n",
    "print(R2)\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", \"training_results\", \"Pearson_CV_xgboost_ESM1b_ts.npy\"), np.array(Pearson))\n",
    "np.save(join(\"..\", \"..\", \"data\",  \"training_results\", \"MSE_CV_xgboost_ESM1b_ts.npy\"), np.array(MSE))\n",
    "np.save(join(\"..\", \"..\", \"data\", \"training_results\", \"R2_CV_xgboost_ESM1b_ts.npy\"), np.array(R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.608 0.905 0.369\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "dtest = xgb.DMatrix(test_X)\n",
    "\n",
    "bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "\n",
    "y_test_pred = bst.predict(dtest)\n",
    "MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "\n",
    "print(np.round(Pearson[0],3) ,np.round(MSE_dif_fp_test,3), np.round(R2_dif_fp_test,3))\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", \"training_results\", \"y_test_pred_xgboost_ESM1b_ts.npy\"), bst.predict(dtest))\n",
    "np.save(join(\"..\", \"..\", \"data\", \"training_results\", \"y_test_true_xgboost_ESM1b_ts.npy\"), test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Training model with test and train data for production mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ESM1b = np.array(list(data_train[\"ESM1b_ts\"]))\n",
    "train_Y = np.array(list(data_train[\"log10_kcat\"]))\n",
    "\n",
    "test_ESM1b = np.array(list(data_test[\"ESM1b_ts\"]))\n",
    "test_Y = np.array(list(data_test[\"log10_kcat\"]))\n",
    "\n",
    "train_X = np.concatenate([train_ESM1b, test_ESM1b])\n",
    "train_Y = np.concatenate([train_Y, test_Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9839122286376513, 0.0) 0.05006636413883383 0.9650757482138885\n"
     ]
    }
   ],
   "source": [
    "param = {'learning_rate': 0.2831145406836757,\n",
    "         'max_delta_step': 0.07686715986169101, \n",
    "         'max_depth': 4.96836783761305,\n",
    "          'min_child_weight': 6.905400087083855,\n",
    "           'num_rounds': 313.1498988074061,\n",
    "            'reg_alpha': 1.717314107718892,\n",
    "             'reg_lambda': 2.470354543039016}\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "\n",
    "del param[\"num_rounds\"]\n",
    "\n",
    "dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "dtest = xgb.DMatrix(test_X)\n",
    "\n",
    "bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "\n",
    "y_test_pred = bst.predict(dtest)\n",
    "MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "\n",
    "print(Pearson, MSE_dif_fp_test, R2_dif_fp_test)\n",
    "\n",
    "pickle.dump(bst, open(join(\"..\", \"..\", \"data\", \"training_results\", \"saved_models\",\n",
    "                          \"xgboost_sequence_only_train_and_test.pkl\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training a model with only reaction information (difference fingerprint):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Creating input matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(list(data_train[\"difference_fp\"]))\n",
    "train_Y = np.array(list(data_train[\"log10_kcat\"]))\n",
    "\n",
    "test_X = np.array(list(data_test[\"difference_fp\"]))\n",
    "test_Y = np.array(list(data_test[\"log10_kcat\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Hyperparameter optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def cross_validation_mse_gradient_boosting(param):\n",
    "    num_round = param[\"num_rounds\"]\n",
    "    del param[\"num_rounds\"]\n",
    "    param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "    param[\"tree_method\"] = \"gpu_hist\"\n",
    "    param[\"sampling_method\"] = \"gradient_based\"\n",
    "    \n",
    "    MSE = []\n",
    "    R2 = []\n",
    "    for i in range(5):\n",
    "        train_index, test_index  = train_indices[i], test_indices[i]\n",
    "        dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "        dvalid = xgb.DMatrix(train_X[test_index])\n",
    "        bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "        y_valid_pred = bst.predict(dvalid)\n",
    "        MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "        R2.append(r2_score(np.reshape(train_Y[test_index], (-1)),  y_valid_pred))\n",
    "    return(-np.mean(R2))\n",
    "\n",
    "\n",
    "from hyperopt import fmin, tpe, rand, hp, Trials\n",
    "\n",
    "space_gradient_boosting = {\n",
    "    \"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 1),\n",
    "    \"max_depth\": hp.uniform(\"max_depth\", 4,12),\n",
    "    #\"subsample\": hp.uniform(\"subsample\", 0.7, 1),\n",
    "    \"reg_lambda\": hp.uniform(\"reg_lambda\", 0, 5),\n",
    "    \"reg_alpha\": hp.uniform(\"reg_alpha\", 0, 5),\n",
    "    \"max_delta_step\": hp.uniform(\"max_delta_step\", 0, 5),\n",
    "    \"min_child_weight\": hp.uniform(\"min_child_weight\", 0.1, 15),\n",
    "    \"num_rounds\":  hp.uniform(\"num_rounds\", 20, 200)}\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn = cross_validation_mse_gradient_boosting, space = space_gradient_boosting,\n",
    "            algo=rand.suggest, max_evals = 200, trials=trials)''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Training and validating model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'learning_rate': 0.14154883958006167,\n",
    "         'max_delta_step': 0.02234358170535966,\n",
    "         'max_depth': 10.869653004093198,\n",
    "         'min_child_weight': 1.7936882442746056,\n",
    "         'num_rounds': 361.6168542774665,\n",
    "         'reg_alpha': 4.825525325323308, \n",
    "         'reg_lambda': 2.74944090578774}\n",
    "\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "\n",
    "del param[\"num_rounds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5933818458131599, 0.5290768248822284, 0.542607402759881, 0.5889341652634299, 0.5248561000592911]\n",
      "[0.8733503195891379, 0.9112072460648096, 0.9525515259896388, 1.0924558329257095, 1.1054594918609029]\n",
      "[0.3353708922662406, 0.27695876037247324, 0.27999083584524465, 0.31871067494359473, 0.2688907919476974]\n"
     ]
    }
   ],
   "source": [
    "R2 = []\n",
    "MSE = []\n",
    "Pearson = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "    dvalid = xgb.DMatrix(train_X[test_index])\n",
    "    \n",
    "    bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "    \n",
    "    y_valid_pred = bst.predict(dvalid)\n",
    "    MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "    R2.append(r2_score(np.reshape(train_Y[test_index], (-1)), y_valid_pred))\n",
    "    Pearson.append(stats.pearsonr(np.reshape(train_Y[test_index], (-1)), y_valid_pred)[0])\n",
    "\n",
    "print(Pearson)\n",
    "print(MSE)\n",
    "print(R2)\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", \"training_results\", \"Pearson_CV_xgboost_diff_fp.npy\"), np.array(Pearson))\n",
    "np.save(join(\"..\", \"..\", \"data\", \"training_results\", \"MSE_CV_xgboost_diff_fp.npy\"), np.array(MSE))\n",
    "np.save(join(\"..\", \"..\", \"data\", \"training_results\", \"R2_CV_xgboost_diff_fp.npy\"), np.array(R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 0.948 0.339\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "dtest = xgb.DMatrix(test_X)\n",
    "\n",
    "bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "\n",
    "y_test_pred = bst.predict(dtest)\n",
    "MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "\n",
    "print(np.round(Pearson[0],3) ,np.round(MSE_dif_fp_test,3), np.round(R2_dif_fp_test,3))\n",
    "\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", \"training_results\", \"y_test_pred_xgboost_diff_fp.npy\"), bst.predict(dtest))\n",
    "np.save(join(\"..\", \"..\", \"data\", \"training_results\", \"y_test_true_xgboost_diff_fp.npy\"), test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training a model with only reaction information (structural fingerprint):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Creating input matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = ();\n",
    "for ind in data_train.index:\n",
    "    train_X = train_X + (np.array(list(data_train[\"structural_fp\"][ind])).astype(int), )\n",
    "train_X = np.array(train_X)\n",
    "train_Y = np.array(list(data_train[\"log10_kcat\"]))\n",
    "\n",
    "\n",
    "test_X = ();\n",
    "for ind in data_test.index:\n",
    "    test_X = test_X + (np.array(list(data_test[\"structural_fp\"][ind])).astype(int), )\n",
    "test_X = np.array(test_X)\n",
    "test_Y = np.array(list(data_test[\"log10_kcat\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Hyperparameter optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def cross_validation_mse_gradient_boosting(param):\n",
    "    num_round = param[\"num_rounds\"]\n",
    "    del param[\"num_rounds\"]\n",
    "    param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "    param[\"tree_method\"] = \"gpu_hist\"\n",
    "    param[\"sampling_method\"] = \"gradient_based\"\n",
    "    \n",
    "    MSE = []\n",
    "    R2 = []\n",
    "    for i in range(5):\n",
    "        train_index, test_index  = train_indices[i], test_indices[i]\n",
    "        dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "        dvalid = xgb.DMatrix(train_X[test_index])\n",
    "        bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "        y_valid_pred = bst.predict(dvalid)\n",
    "        MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "        R2.append(r2_score(np.reshape(train_Y[test_index], (-1)),  y_valid_pred))\n",
    "    return(-np.mean(R2))\n",
    "\n",
    "\n",
    "from hyperopt import fmin, tpe, rand, hp, Trials\n",
    "\n",
    "space_gradient_boosting = {\n",
    "    \"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 1),\n",
    "    \"max_depth\": hp.uniform(\"max_depth\", 4,12),\n",
    "    #\"subsample\": hp.uniform(\"subsample\", 0.7, 1),\n",
    "    \"reg_lambda\": hp.uniform(\"reg_lambda\", 0, 5),\n",
    "    \"reg_alpha\": hp.uniform(\"reg_alpha\", 0, 5),\n",
    "    \"max_delta_step\": hp.uniform(\"max_delta_step\", 0, 5),\n",
    "    \"min_child_weight\": hp.uniform(\"min_child_weight\", 0.1, 15),\n",
    "    \"num_rounds\":  hp.uniform(\"num_rounds\", 20, 200)}\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn = cross_validation_mse_gradient_boosting, space = space_gradient_boosting,\n",
    "            algo=rand.suggest, max_evals = 200, trials=trials)''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Training and validating model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'learning_rate': 0.01126910440903659,\n",
    "         'max_delta_step': 0.5777120839605732,\n",
    "         'max_depth': 5.486901609313889,\n",
    "         'min_child_weight': 6.14467742389769,\n",
    "         'num_rounds': 488.943459090126,\n",
    "         'reg_alpha': 4.629840853377147,\n",
    "         'reg_lambda': 2.1047561335691745}\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "\n",
    "del param[\"num_rounds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5536292775258077, 0.532314381623744, 0.4889091394899996, 0.61040565169482, 0.5039256159780713]\n",
      "[0.917613544024189, 0.9056644419444148, 1.015607786275439, 1.064522657133946, 1.1289411204418558]\n",
      "[0.3016860962550283, 0.2813569650394473, 0.23232823280029657, 0.3361306693344771, 0.2533609285723336]\n"
     ]
    }
   ],
   "source": [
    "R2 = []\n",
    "MSE = []\n",
    "Pearson = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "    dvalid = xgb.DMatrix(train_X[test_index])\n",
    "    \n",
    "    bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "    \n",
    "    y_valid_pred = bst.predict(dvalid)\n",
    "    MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "    R2.append(r2_score(np.reshape(train_Y[test_index], (-1)), y_valid_pred))\n",
    "    Pearson.append(stats.pearsonr(np.reshape(train_Y[test_index], (-1)), y_valid_pred)[0])\n",
    "\n",
    "print(Pearson)\n",
    "print(MSE)\n",
    "print(R2)\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", \"training_results\", \"Pearson_CV_xgboost_str_fp.npy\"), np.array(Pearson))\n",
    "np.save(join(\"..\", \"..\", \"data\", \"training_results\", \"MSE_CV_xgboost_str_fp.npy\"), np.array(MSE))\n",
    "np.save(join(\"..\", \"..\", \"data\", \"training_results\", \"R2_CV_xgboost_str_fp.npy\"), np.array(R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.561 0.994 0.307\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "dtest = xgb.DMatrix(test_X)\n",
    "\n",
    "bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "\n",
    "y_test_pred = bst.predict(dtest)\n",
    "MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "\n",
    "print(np.round(Pearson[0],3) ,np.round(MSE_dif_fp_test,3), np.round(R2_dif_fp_test,3))\n",
    "\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", \"training_results\", \"y_test_pred_xgboost_str_fp.npy\"), bst.predict(dtest))\n",
    "np.save(join(\"..\", \"..\", \"data\", \"training_results\", \"y_test_true_xgboost_str_fp.npy\"), test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training a model with enzyme and reaction information (ESM1b_ts/diff_fp):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Creating input matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(list(data_train[\"difference_fp\"]))\n",
    "train_X = np.concatenate([train_X, np.array(list(data_train[\"ESM1b_ts\"]))], axis = 1)\n",
    "train_Y = np.array(list(data_train[\"log10_kcat\"]))\n",
    "\n",
    "test_X = np.array(list(data_test[\"difference_fp\"]))\n",
    "test_X = np.concatenate([test_X, np.array(list(data_test[\"ESM1b_ts\"]))], axis = 1)\n",
    "test_Y = np.array(list(data_test[\"log10_kcat\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Hyperparameter optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def cross_validation_mse_gradient_boosting(param):\n",
    "    num_round = param[\"num_rounds\"]\n",
    "    del param[\"num_rounds\"]\n",
    "    param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "    param[\"tree_method\"] = \"gpu_hist\"\n",
    "    param[\"sampling_method\"] = \"gradient_based\"\n",
    "    \n",
    "    MSE = []\n",
    "    R2 = []\n",
    "    for i in range(5):\n",
    "        train_index, test_index  = train_indices[i], test_indices[i]\n",
    "        dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "        dvalid = xgb.DMatrix(train_X[test_index])\n",
    "        bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "        y_valid_pred = bst.predict(dvalid)\n",
    "        MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "        R2.append(r2_score(np.reshape(train_Y[test_index], (-1)),  y_valid_pred))\n",
    "    return(-np.mean(R2))\n",
    "\n",
    "\n",
    "from hyperopt import fmin, tpe, rand, hp, Trials\n",
    "\n",
    "space_gradient_boosting = {\n",
    "    \"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 1),\n",
    "    \"max_depth\": hp.uniform(\"max_depth\", 4,12),\n",
    "    #\"subsample\": hp.uniform(\"subsample\", 0.7, 1),\n",
    "    \"reg_lambda\": hp.uniform(\"reg_lambda\", 0, 5),\n",
    "    \"reg_alpha\": hp.uniform(\"reg_alpha\", 0, 5),\n",
    "    \"max_delta_step\": hp.uniform(\"max_delta_step\", 0, 5),\n",
    "    \"min_child_weight\": hp.uniform(\"min_child_weight\", 0.1, 15),\n",
    "    \"num_rounds\":  hp.uniform(\"num_rounds\", 20, 200)}\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn = cross_validation_mse_gradient_boosting, space = space_gradient_boosting,\n",
    "            algo=rand.suggest, max_evals = 200, trials=trials)''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Training and validating model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'learning_rate': 0.5727401435817077, \n",
    "         'max_delta_step': 0.022572978136953803,\n",
    "         'max_depth': 9.734956573895278,\n",
    "         'min_child_weight': 2.026404280518698,\n",
    "         'num_rounds': 259.69265795096726,\n",
    "         'reg_alpha': 7.333074414515098,\n",
    "         'reg_lambda': 0.8545111451043885}\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "\n",
    "del param[\"num_rounds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6445379171956692, 0.5663538267118359, 0.5813292687854973, 0.6603671022176677, 0.5437710214323066]\n",
      "[0.7778549566615786, 0.8621287188783706, 0.8811802952099859, 0.9212592601438562, 1.0674061317478523]\n",
      "[0.40804390380771904, 0.31590247958588724, 0.33393851092241733, 0.4254741650612315, 0.2940578488872041]\n"
     ]
    }
   ],
   "source": [
    "R2 = []\n",
    "MSE = []\n",
    "Pearson = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "    dvalid = xgb.DMatrix(train_X[test_index])\n",
    "    \n",
    "    bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "    \n",
    "    y_valid_pred = bst.predict(dvalid)\n",
    "    MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "    R2.append(r2_score(np.reshape(train_Y[test_index], (-1)), y_valid_pred))\n",
    "    Pearson.append(stats.pearsonr(np.reshape(train_Y[test_index], (-1)), y_valid_pred)[0])\n",
    "\n",
    "print(Pearson)\n",
    "print(MSE)\n",
    "print(R2)\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", \"training_results\", \"Pearson_CV_xgboost_ESM1b_ts_diff_fp.npy\"), np.array(Pearson))\n",
    "np.save(join(\"..\", \"..\", \"data\", \"training_results\", \"MSE_CV_xgboost_ESM1b_ts_diff_fp.npy\"), np.array(MSE))\n",
    "np.save(join(\"..\", \"..\", \"data\", \"training_results\", \"R2_CV_xgboost_ESM1b_ts_diff_fp.npy\"), np.array(R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.629 0.868 0.394\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "dtest = xgb.DMatrix(test_X, label = test_Y)\n",
    "\n",
    "\n",
    "bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "\n",
    "y_test_pred = bst.predict(dtest)\n",
    "MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "\n",
    "print(np.round(Pearson[0],3) ,np.round(MSE_dif_fp_test,3), np.round(R2_dif_fp_test,3))\n",
    "\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", \"training_results\", \"y_test_pred_xgboost_ESM1b_ts_diff_fp.npy\"), bst.predict(dtest))\n",
    "np.save(join(\"..\", \"..\", \"data\", \"training_results\", \"y_test_true_xgboost_ESM1b_ts_diff_fp.npy\"), test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Training model with test and train data for production mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(list(data_train[\"difference_fp\"]))\n",
    "train_X = np.concatenate([train_X, np.array(list(data_train[\"ESM1b_ts\"]))], axis = 1)\n",
    "train_Y = np.array(list(data_train[\"log10_kcat\"]))\n",
    "\n",
    "test_X = np.array(list(data_test[\"difference_fp\"]))\n",
    "test_X = np.concatenate([test_X, np.array(list(data_test[\"ESM1b_ts\"]))], axis = 1)\n",
    "test_Y = np.array(list(data_test[\"log10_kcat\"]))\n",
    "\n",
    "train_X = np.concatenate([train_X, test_X])\n",
    "train_Y = np.concatenate([train_Y, test_Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9910659621749647, 0.0) 0.027904669605058757 0.9805348416235519\n"
     ]
    }
   ],
   "source": [
    "param = {'learning_rate': 0.5727401435817077, \n",
    "         'max_delta_step': 0.022572978136953803,\n",
    "         'max_depth': 9.734956573895278,\n",
    "         'min_child_weight': 2.026404280518698,\n",
    "         'num_rounds': 259.69265795096726,\n",
    "         'reg_alpha': 7.333074414515098,\n",
    "         'reg_lambda': 0.8545111451043885}\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "\n",
    "del param[\"num_rounds\"]\n",
    "\n",
    "dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "dtest = xgb.DMatrix(test_X)\n",
    "\n",
    "bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "\n",
    "y_test_pred = bst.predict(dtest)\n",
    "MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "\n",
    "print(Pearson, MSE_dif_fp_test, R2_dif_fp_test)\n",
    "\n",
    "pickle.dump(bst, open(join(\"..\", \"..\", \"data\", \"training_results\", \"saved_models\",\n",
    "                          \"xgboost_train_and_test.pkl\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training a model with enzyme rep., reaction information, and additional features (ESM1b_ts/diff_fp/flux/KM):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading dataset with additonal features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3421, 850)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_pickle(join(\"..\", \"..\", \"data\", \"kcat_data\", \"splits\", \"train_df_kcat_with_KM_and_flux.pkl\"))\n",
    "data_test = pd.read_pickle(join(\"..\", \"..\", \"data\", \"kcat_data\", \"splits\", \"test_df_kcat_with_KM_and_flux.pkl\"))\n",
    "\n",
    "data_train.rename(columns = {\"geomean_kcat\" :\"log10_kcat\"}, inplace = True)\n",
    "data_test.rename(columns = {\"geomean_kcat\" :\"log10_kcat\"}, inplace = True)\n",
    "len(data_train), len(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = ();\n",
    "train_X = np.array(list(data_train[\"difference_fp\"]))\n",
    "train_X = np.concatenate([train_X, np.array(list(data_train[\"ESM1b_ts\"])),\n",
    "                          np.reshape(np.array(list(data_train[\"KM\"])), (-1,1)),\n",
    "                          np.reshape(np.array(list(data_train[\"flux\"])), (-1,1))], axis = 1)\n",
    "train_Y = np.array(list(data_train[\"log10_kcat\"]))\n",
    "\n",
    "test_X = ();\n",
    "test_X = np.array(list(data_test[\"difference_fp\"]))\n",
    "test_X = np.concatenate([test_X, np.array(list(data_test[\"ESM1b_ts\"])),\n",
    "                          np.reshape(np.array(list(data_test[\"KM\"])), (-1,1)),\n",
    "                          np.reshape(np.array(list(data_test[\"flux\"])), (-1,1))], axis = 1)\n",
    "test_Y = np.array(list(data_test[\"log10_kcat\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def cross_validation_mse_gradient_boosting(param):\n",
    "    num_round = param[\"num_rounds\"]\n",
    "    del param[\"num_rounds\"]\n",
    "    param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "    param[\"tree_method\"] = \"gpu_hist\"\n",
    "    param[\"sampling_method\"] = \"gradient_based\"\n",
    "    \n",
    "    MSE = []\n",
    "    R2 = []\n",
    "    for i in range(5):\n",
    "        train_index, test_index  = train_indices[i], test_indices[i]\n",
    "        dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "        dvalid = xgb.DMatrix(train_X[test_index])\n",
    "        bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "        y_valid_pred = bst.predict(dvalid)\n",
    "        MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "        R2.append(r2_score(np.reshape(train_Y[test_index], (-1)),  y_valid_pred))\n",
    "    return(-np.mean(R2))\n",
    "\n",
    "\n",
    "from hyperopt import fmin, tpe, rand, hp, Trials\n",
    "\n",
    "space_gradient_boosting = {\n",
    "    \"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 1),\n",
    "    \"max_depth\": hp.uniform(\"max_depth\", 4,12),\n",
    "    #\"subsample\": hp.uniform(\"subsample\", 0.7, 1),\n",
    "    \"reg_lambda\": hp.uniform(\"reg_lambda\", 0, 5),\n",
    "    \"reg_alpha\": hp.uniform(\"reg_alpha\", 0, 5),\n",
    "    \"max_delta_step\": hp.uniform(\"max_delta_step\", 0, 5),\n",
    "    \"min_child_weight\": hp.uniform(\"min_child_weight\", 0.1, 15),\n",
    "    \"num_rounds\":  hp.uniform(\"num_rounds\", 20, 200)}\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn = cross_validation_mse_gradient_boosting, space = space_gradient_boosting,\n",
    "            algo=rand.suggest, max_evals = 200, trials=trials)''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'learning_rate': 0.15055870206296312,\n",
    "         'max_delta_step': 0.13821534396910307,\n",
    "         'max_depth': 5.338955142881738,\n",
    "         'min_child_weight': 14.84613730467497,\n",
    "         'num_rounds': 294.13028718637383,\n",
    "         'reg_alpha': 2.6752278199969153,\n",
    "         'reg_lambda': 0.6063171152564584}\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"max_depth\"] = int(np.round(param[\"max_depth\"]))\n",
    "\n",
    "del param[\"num_rounds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6381726941853013, 0.5782540928851373, 0.5816409524748034, 0.6501114403040922, 0.5359555917016532]\n",
      "[0.7820629557858503, 0.843033028077367, 0.8823309866269835, 0.9415727118823687, 1.085306625916712]\n",
      "[0.40484157063101067, 0.33105487439829584, 0.33306873291802874, 0.412806066811956, 0.28221913728185244]\n"
     ]
    }
   ],
   "source": [
    "R2 = []\n",
    "MSE = []\n",
    "Pearson = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    dtrain = xgb.DMatrix(train_X[train_index], label = train_Y[train_index])\n",
    "    dvalid = xgb.DMatrix(train_X[test_index])\n",
    "    \n",
    "    bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "    \n",
    "    y_valid_pred = bst.predict(dvalid)\n",
    "    MSE.append(np.mean(abs(np.reshape(train_Y[test_index], (-1)) - y_valid_pred)**2))\n",
    "    R2.append(r2_score(np.reshape(train_Y[test_index], (-1)), y_valid_pred))\n",
    "    Pearson.append(stats.pearsonr(np.reshape(train_Y[test_index], (-1)), y_valid_pred)[0])\n",
    "\n",
    "print(Pearson)\n",
    "print(MSE)\n",
    "print(R2)\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", \"training_results\", \"Pearson_CV_xgboost_ESM1b_diff_fp_flux_KM.npy\"), np.array(Pearson))\n",
    "np.save(join(\"..\", \"..\", \"data\", \"training_results\", \"MSE_CV_xgboost_ESM1b_diff_fp_flux_KM.npy\"), np.array(MSE))\n",
    "np.save(join(\"..\", \"..\", \"data\", \"training_results\", \"R2_CV_xgboost_ESM1b_diff_fp_flux_KM.npy\"), np.array(R2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6203728110199708 0.8836397180206959 0.3836090051439036\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(train_X, label = train_Y)\n",
    "dtest = xgb.DMatrix(test_X)\n",
    "\n",
    "bst = xgb.train(param, dtrain, int(num_round), verbose_eval=False)\n",
    "\n",
    "y_test_pred = bst.predict(dtest)\n",
    "MSE_dif_fp_test = np.mean(abs(np.reshape(test_Y, (-1)) - y_test_pred)**2)\n",
    "R2_dif_fp_test = r2_score(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "Pearson = stats.pearsonr(np.reshape(test_Y, (-1)), y_test_pred)\n",
    "\n",
    "print(Pearson[0], MSE_dif_fp_test, R2_dif_fp_test)\n",
    "\n",
    "\n",
    "np.save(join(\"..\", \"..\", \"data\", \"training_results\", \"y_test_pred_xgboost_ESM1b_diff_fp_flux_KM.npy\"), bst.predict(dtest))\n",
    "np.save(join(\"..\", \"..\", \"data\", \"training_results\", \"y_test_true_xgboost_ESM1b_diff_fp_flux_KM.npy\"), test_Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
